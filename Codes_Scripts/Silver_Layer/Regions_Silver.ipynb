{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b4fc9907-14f0-4938-a6c8-e14917a0894f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# \uD83E\uDD48 **Silver Layer: Data Cleaning & Standardization**\n",
    "\n",
    "\n",
    "The **Silver Layer** represents the \"Cleaned\" and \"Validated\" state of our data. In this stage, we transform the raw Bronze data into a queryable format by applying a strict sequence of cleaning and casting operations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3e74c6c4-168d-46e5-9cbb-f302466395be",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# \uD83D\uDE80 ETL Transformation: Regions Silver Layer\n",
    "**Objective:** Standardize geographical data by cleaning state codes and removing redundant regional records.\n",
    "\n",
    "---\n",
    "\n",
    "### âœ… Summary of Transformation Steps\n",
    "| Step | Operation | Tool |\n",
    "| :--- | :--- | :--- |\n",
    "| **1** | String Cleaning | Pandas `.str.strip()` |\n",
    "| **2** | Deduplication | Pandas `.drop_duplicates()` |\n",
    "| **3** | Rename Columns | Pandas `.rename()` |\n",
    "| **4** | Data Type Mapping | Spark `createDataFrame()` |\n",
    "| **5** | Silver Layer Save | Delta Lake Table |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ef3ff9d6-ea9b-40ed-be7d-587755504662",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 1. Data Acquisition & Environment Transition\n",
    "The process began by loading the raw regional data from the Bronze Layer into a Spark DataFrame, which was then converted to Pandas to facilitate granular string manipulation.\n",
    "* **Source Table:** `sales.bronz_layer.regions`\n",
    "* **Method:** `.toPandas()` for high-performance localized cleaning.\n",
    "\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ec8692da-058e-4328-81ae-45ac1cea834c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>StateCode</th>\n",
       "      <th>State</th>\n",
       "      <th>Region</th>\n",
       "      <th>ingestion_data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AL</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>South</td>\n",
       "      <td>2026-02-02 12:53:43.463978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AR</td>\n",
       "      <td>Arkansas</td>\n",
       "      <td>South</td>\n",
       "      <td>2026-02-02 12:53:43.463978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AZ</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>West</td>\n",
       "      <td>2026-02-02 12:53:43.463978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CA</td>\n",
       "      <td>California</td>\n",
       "      <td>West</td>\n",
       "      <td>2026-02-02 12:53:43.463978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CO</td>\n",
       "      <td>Colorado</td>\n",
       "      <td>West</td>\n",
       "      <td>2026-02-02 12:53:43.463978</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  StateCode       State Region             ingestion_data\n",
       "0       AL      Alabama  South 2026-02-02 12:53:43.463978\n",
       "1        AR    Arkansas  South 2026-02-02 12:53:43.463978\n",
       "2        AZ     Arizona   West 2026-02-02 12:53:43.463978\n",
       "3        CA  California   West 2026-02-02 12:53:43.463978\n",
       "4        CO   Colorado    West 2026-02-02 12:53:43.463978"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import pyspark.sql.functions as f\n",
    "\n",
    "regions = spark.read.table(\"sales.bronz_layer.regions\")\n",
    "regions = regions.toPandas()\n",
    "print(type(regions))\n",
    "regions.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "06815d7a-4080-4f4f-b63d-bac6e8107cd9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 2. Automated Whitespace Trimming\n",
    "Geographical codes (like State Codes) are highly sensitive to hidden spaces which can break future map visualizations or joins with sales data.\n",
    "* **Detection:** Identified all columns with `object` (string) data types.\n",
    "* **Action:** Iterated through all string columns using `.str.strip()` to remove leading and trailing spaces.\n",
    "* **Result:** Ensured consistency across codes (e.g., `\" NY\"` and `\"NY \"` were standardized to `\"NY\"`).\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "871bbe03-7593-4d25-91d7-eb0b94396d1d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trimmed 3 columns : ['StateCode', 'State', 'Region']\n"
     ]
    }
   ],
   "source": [
    "# identify columns contain texts \n",
    "string_columns = regions.select_dtypes(include = ['object']).columns\n",
    "# loop through and trim leading and traialing whitespaces \n",
    "for col in string_columns: \n",
    "    regions[col] = regions[col].astype(str).str.strip()\n",
    "\n",
    "print(f\"Trimmed {len(string_columns)} columns : {list(string_columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "31f30219-5ce9-4922-b470-60a01722f7f7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 3. Regional Deduplication\n",
    "After cleaning the string columns, the dataset was scanned for duplicate rows that may have been introduced during the data entry phase in the source systems.\n",
    "* **Process:** * Calculated initial row count vs. duplicate count using `.duplicated().sum()`.\n",
    "    * Removed duplicates while retaining the `first` occurrence.\n",
    "* **Integrity:** Executed `.reset_index(drop=True)` to ensure a continuous index for the cleaned dataset.\n",
    "\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "78549b04-f2a3-417a-94a2-f9be63c3719a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lenght of dataframe 52\nfound4 duplicated rows\nlength after removing duplicates 48\n"
     ]
    }
   ],
   "source": [
    "print(f\"lenght of dataframe {len(regions)}\")\n",
    "duplicate_count= regions.duplicated().sum() #count duplicated rows\n",
    "print(f\"found{duplicate_count} duplicated rows\")\n",
    "regions = regions.drop_duplicates(keep = 'first')\n",
    "regions = regions.reset_index(drop = True) \n",
    "print (f\"length after removing duplicates {len(regions)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b779d44e-4bd4-422c-8405-6bf49663ed15",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 4. Schema Refinement & Naming Conventions\n",
    "To ensure the table is \"Business Ready\" and matches the Silver Layer naming standards:\n",
    "* **Renaming:** Converted `StateCode` to `State_Code`.\n",
    "* **Standardization:** Applied snake_case formatting to improve readability for SQL analysts and BI tools.\n",
    "\n",
    "---\n",
    "\n",
    "### 5. Delta Lake Finalization\n",
    "The processed data was converted back into a Spark DataFrame and written to the Delta Lake.\n",
    "* **Storage Format:** **Delta** (Enabling Time Travel and ACID transactions).\n",
    "* **Write Strategy:** `.mode(\"overwrite\")` combined with `.option(\"overwriteSchema\", \"true\")`.\n",
    "* **Destination:** `sales.silver_layer.regions`\n",
    "\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "db4ace43-2a8e-4e69-9ecb-2b5c91f360ea",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "regions = regions.rename(columns = {\n",
    "    'StateCode' : \"State_Code\"\n",
    "})\n",
    "\n",
    "regions_spark = spark.createDataFrame(regions)\n",
    "regions_spark.write\\\n",
    "    .mode(\"overwrite\")\\\n",
    "    .format(\"delta\")\\\n",
    "    .option(\"overwriteSchema\",\"true\")\\\n",
    "    .saveAsTable(\"sales.silver_layer.regions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3229af77-a19b-4b20-8852-831a7f2ed970",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## **sanity check of silver table**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "84ed4a84-dd12-42cc-97fe-4a24c9159a25",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>State_Code</th><th>State</th><th>Region</th><th>ingestion_data</th></tr></thead><tbody><tr><td>AL</td><td>Alabama</td><td>South</td><td>2026-02-02T12:53:43.463Z</td></tr><tr><td>AR</td><td>Arkansas</td><td>South</td><td>2026-02-02T12:53:43.463Z</td></tr><tr><td>AZ</td><td>Arizona</td><td>West</td><td>2026-02-02T12:53:43.463Z</td></tr><tr><td>CA</td><td>California</td><td>West</td><td>2026-02-02T12:53:43.463Z</td></tr><tr><td>CO</td><td>Colorado</td><td>West</td><td>2026-02-02T12:53:43.463Z</td></tr><tr><td>CT</td><td>Connecticut</td><td>Northeast</td><td>2026-02-02T12:53:43.463Z</td></tr><tr><td>DC</td><td>District of Columbia</td><td>South</td><td>2026-02-02T12:53:43.463Z</td></tr><tr><td>DE</td><td>Delaware</td><td>South</td><td>2026-02-02T12:53:43.463Z</td></tr><tr><td>FL</td><td>Florida</td><td>South</td><td>2026-02-02T12:53:43.463Z</td></tr><tr><td>GA</td><td>Georgia</td><td>South</td><td>2026-02-02T12:53:43.463Z</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "AL",
         "Alabama",
         "South",
         "2026-02-02T12:53:43.463Z"
        ],
        [
         "AR",
         "Arkansas",
         "South",
         "2026-02-02T12:53:43.463Z"
        ],
        [
         "AZ",
         "Arizona",
         "West",
         "2026-02-02T12:53:43.463Z"
        ],
        [
         "CA",
         "California",
         "West",
         "2026-02-02T12:53:43.463Z"
        ],
        [
         "CO",
         "Colorado",
         "West",
         "2026-02-02T12:53:43.463Z"
        ],
        [
         "CT",
         "Connecticut",
         "Northeast",
         "2026-02-02T12:53:43.463Z"
        ],
        [
         "DC",
         "District of Columbia",
         "South",
         "2026-02-02T12:53:43.463Z"
        ],
        [
         "DE",
         "Delaware",
         "South",
         "2026-02-02T12:53:43.463Z"
        ],
        [
         "FL",
         "Florida",
         "South",
         "2026-02-02T12:53:43.463Z"
        ],
        [
         "GA",
         "Georgia",
         "South",
         "2026-02-02T12:53:43.463Z"
        ]
       ],
       "datasetInfos": [
        {
         "name": "_sqldf",
         "schema": {
          "fields": [
           {
            "metadata": {},
            "name": "State_Code",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "State",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "Region",
            "nullable": true,
            "type": "string"
           },
           {
            "metadata": {},
            "name": "ingestion_data",
            "nullable": true,
            "type": "timestamp"
           }
          ],
          "type": "struct"
         },
         "tableIdentifier": null,
         "typeStr": "pyspark.sql.connect.dataframe.DataFrame"
        }
       ],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "createTempViewForImplicitDf": true,
        "dataframeName": "_sqldf",
        "executionCount": 28
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "State_Code",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "State",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "Region",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "ingestion_data",
         "type": "\"timestamp\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "SELECT * FROM sales.silver_layer.regions LIMIT 10;"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 8710734218339417,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "Regions_Silver",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}